{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vision_Transformers_for_Strong_Lensing_Parameters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshualin24/Lens_Finder/blob/master/Vision_Transformers_for_Strong_Lensing_Parameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSb9tLDKCMGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5734666-ad19-4aa7-f14f-1a60074a284f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1SOTxsao-uEVVYslV76SRXz66Gw3IntqV/Deep_Cosmos_AI/DeepLense/Strong-Lensing-ViT\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Deep_Cosmos_AI/DeepLense/Strong-Lensing-ViT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.transform import resize\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "UZWed9HXE41S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_paths, use_pretrain=True):\n",
        "        super(CustomDataset, self).__init__()\n",
        "        self.use_pretrain = use_pretrain\n",
        "\n",
        "        self.data_samples = []\n",
        "        for path in data_paths:\n",
        "            print(f\"Loading `{path}`...\")\n",
        "            self.data_samples.extend(np.load(path, allow_pickle=True))\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, parameters = self.data_samples[0]\n",
        "\n",
        "        if self.use_pretrain:\n",
        "            image = resize(image, (224, 224))\n",
        "        image = torch.from_numpy(image).type(torch.float32)\n",
        "        image = torch.stack([image, image, image], axis=0)\n",
        "        parameters = torch.from_numpy(parameters).type(torch.float32)\n",
        "    \n",
        "        return image, parameters\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_samples)"
      ],
      "metadata": {
        "id": "CMWfkyKPD7pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        # ==============\n",
        "        # Model training\n",
        "        # ==============\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        num_images = 0\n",
        "        model.train() # Set model to training mode\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            num_images += inputs.shape[0]\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            # running_corrects += torch.sum(preds == labels.data)\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(\"Batch {}/{} -> Loss: {:.8f}\".format(batch_idx, len(train_loader), loss.item()))\n",
        "\n",
        "        scheduler.step()\n",
        "        train_loss = running_loss / num_images\n",
        "        # train_acc = running_corrects.double() / num_images\n",
        "\n",
        "        # ================\n",
        "        # Model Validation\n",
        "        # ================\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        num_images = 0\n",
        "        model.eval() # Set model to evaluate mode\n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.set_grad_enabled(False):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            num_images += inputs.shape[0]\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            # running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_loss = running_loss / num_images\n",
        "        # val_acc = running_corrects.double() / num_images\n",
        "\n",
        "        print(\"Epoch [{:2d}/{:2d}] Train Loss: {:.8f}| Val Loss: {:.8f}\".format(\n",
        "            epoch, num_epochs, train_loss, val_loss))\n",
        "        # if val_acc > best_acc:\n",
        "        #     best_acc = val_acc\n",
        "        #     best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    # print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    # model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "SF97I4P1S9qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_dir = \"./datasets/npy_files\"\n",
        "# metadata_path = \"./datasets/metadata.csv\"\n",
        "# rqrd_params = [\n",
        "#     \"theta_E\", \"gamma\", \"center_x\", \"center_y\", \n",
        "#     \"e1\", \"e2\", \"gamma_ext\", \"psi_ext\", \n",
        "#     \"lens_light_n_sersic\", \"lens_light_R_sersic\"\n",
        "# ]\n",
        "\n",
        "batch_size = 64\n",
        "num_outputs_params = 10\n",
        "learing_rate = 1e-4\n",
        "step_size = 10\n",
        "num_epochs = 20\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "g-21QTX4DmxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths = glob.glob(\"./datasets/train/*.npy\")[:4]\n",
        "valid_paths = glob.glob(\"./datasets/validation/*.npy\")\n",
        "train_paths, valid_paths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7smoO15TD2b1",
        "outputId": "56daf41f-05df-467e-8b63-f375fa674626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['./datasets/train/train_meta-0.npy',\n",
              "  './datasets/train/train_meta-1.npy',\n",
              "  './datasets/train/train_meta-2.npy',\n",
              "  './datasets/train/train_meta-3.npy'],\n",
              " ['./datasets/validation/valid_meta.npy'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_paths)\n",
        "valid_dataset = CustomDataset(valid_paths)\n",
        "\n"
      ],
      "metadata": {
        "id": "X71zze0HES3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8a66ac-04ce-442a-a054-cfb16a93296b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading `./datasets/train/train_meta-0.npy`...\n",
            "Loading `./datasets/train/train_meta-1.npy`...\n",
            "Loading `./datasets/train/train_meta-2.npy`...\n",
            "Loading `./datasets/train/train_meta-3.npy`...\n",
            "Loading `./datasets/validation/valid_meta.npy`...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "t3hfJ4rVcHv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=False)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features=num_ftrs, out_features=num_outputs_params)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss(reduction=\"mean\")\n",
        "optimizer = optim.Adam(model.parameters(), lr=learing_rate)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)"
      ],
      "metadata": {
        "id": "XyCePuRhEvaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_WS2R_7cVv1B",
        "outputId": "75b89db5-9c17-48d0-a1ea-0e0150ff9ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/188 -> Loss: 5.04981947\n",
            "Batch 10/188 -> Loss: 0.02691992\n",
            "Batch 20/188 -> Loss: 0.00591745\n",
            "Batch 30/188 -> Loss: 0.00019096\n",
            "Batch 40/188 -> Loss: 0.00002119\n",
            "Batch 50/188 -> Loss: 0.00002962\n",
            "Batch 60/188 -> Loss: 0.00001738\n",
            "Batch 70/188 -> Loss: 0.00000057\n",
            "Batch 80/188 -> Loss: 0.00000180\n",
            "Batch 90/188 -> Loss: 0.00000037\n",
            "Batch 100/188 -> Loss: 0.00000018\n",
            "Batch 110/188 -> Loss: 0.00000006\n",
            "Batch 120/188 -> Loss: 0.00000003\n",
            "Batch 130/188 -> Loss: 0.00000000\n",
            "Batch 140/188 -> Loss: 0.00000000\n",
            "Batch 150/188 -> Loss: 0.00000000\n",
            "Batch 160/188 -> Loss: 0.00000000\n",
            "Batch 170/188 -> Loss: 0.00000000\n",
            "Batch 180/188 -> Loss: 0.00000000\n",
            "Epoch [ 1/20] Train Loss: 0.09916129| Val Loss: 0.00000382\n",
            "Batch 0/188 -> Loss: 0.00000000\n",
            "Batch 10/188 -> Loss: 0.00000000\n",
            "Batch 20/188 -> Loss: 0.00000000\n",
            "Batch 30/188 -> Loss: 0.00000000\n",
            "Batch 40/188 -> Loss: 0.00000000\n",
            "Batch 50/188 -> Loss: 0.00000000\n",
            "Batch 60/188 -> Loss: 0.00000000\n",
            "Batch 70/188 -> Loss: 0.00000000\n",
            "Batch 80/188 -> Loss: 0.00000000\n",
            "Batch 90/188 -> Loss: 0.00000000\n",
            "Batch 100/188 -> Loss: 0.00000000\n",
            "Batch 110/188 -> Loss: 0.00000000\n",
            "Batch 120/188 -> Loss: 0.00000000\n",
            "Batch 130/188 -> Loss: 0.00000000\n",
            "Batch 140/188 -> Loss: 0.00000000\n",
            "Batch 150/188 -> Loss: 0.00000000\n",
            "Batch 160/188 -> Loss: 0.00000000\n",
            "Batch 170/188 -> Loss: 0.00000000\n",
            "Batch 180/188 -> Loss: 0.00000000\n",
            "Epoch [ 2/20] Train Loss: 0.00000000| Val Loss: 0.00000383\n",
            "Batch 0/188 -> Loss: 0.00000000\n",
            "Batch 10/188 -> Loss: 0.00000000\n",
            "Batch 20/188 -> Loss: 0.00000000\n",
            "Batch 30/188 -> Loss: 0.00000000\n",
            "Batch 40/188 -> Loss: 0.00000000\n",
            "Batch 50/188 -> Loss: 0.00000000\n",
            "Batch 60/188 -> Loss: 0.00000000\n",
            "Batch 70/188 -> Loss: 0.00000000\n",
            "Batch 80/188 -> Loss: 0.00000000\n",
            "Batch 90/188 -> Loss: 0.00000000\n",
            "Batch 100/188 -> Loss: 0.00000000\n",
            "Batch 110/188 -> Loss: 0.00000000\n",
            "Batch 120/188 -> Loss: 0.00000000\n",
            "Batch 130/188 -> Loss: 0.00000000\n",
            "Batch 140/188 -> Loss: 0.00000000\n",
            "Batch 150/188 -> Loss: 0.00000000\n",
            "Batch 160/188 -> Loss: 0.00000000\n",
            "Batch 170/188 -> Loss: 0.00000000\n",
            "Batch 180/188 -> Loss: 0.00000000\n",
            "Epoch [ 3/20] Train Loss: 0.00000000| Val Loss: 0.00000383\n",
            "Batch 0/188 -> Loss: 0.00000000\n",
            "Batch 10/188 -> Loss: 0.00000000\n",
            "Batch 20/188 -> Loss: 0.00000000\n",
            "Batch 30/188 -> Loss: 0.00000000\n",
            "Batch 40/188 -> Loss: 0.00000000\n",
            "Batch 50/188 -> Loss: 0.00000000\n",
            "Batch 60/188 -> Loss: 0.00000000\n",
            "Batch 70/188 -> Loss: 0.00000000\n",
            "Batch 80/188 -> Loss: 0.00000000\n",
            "Batch 90/188 -> Loss: 0.00000000\n",
            "Batch 100/188 -> Loss: 0.00000000\n",
            "Batch 110/188 -> Loss: 0.00000000\n",
            "Batch 120/188 -> Loss: 0.00000000\n",
            "Batch 130/188 -> Loss: 0.00000000\n",
            "Batch 140/188 -> Loss: 0.00000000\n",
            "Batch 150/188 -> Loss: 0.00000000\n",
            "Batch 160/188 -> Loss: 0.00000000\n",
            "Batch 170/188 -> Loss: 0.00000000\n",
            "Batch 180/188 -> Loss: 0.00000000\n",
            "Epoch [ 4/20] Train Loss: 0.00000000| Val Loss: 0.00000383\n",
            "Batch 0/188 -> Loss: 0.00000000\n",
            "Batch 10/188 -> Loss: 0.00000000\n",
            "Batch 20/188 -> Loss: 0.00000000\n",
            "Batch 30/188 -> Loss: 0.00000000\n",
            "Batch 40/188 -> Loss: 0.00000000\n",
            "Batch 50/188 -> Loss: 0.00000000\n",
            "Batch 60/188 -> Loss: 0.00000000\n",
            "Batch 70/188 -> Loss: 0.00000000\n",
            "Batch 80/188 -> Loss: 0.00000000\n",
            "Batch 90/188 -> Loss: 0.00000002\n",
            "Batch 100/188 -> Loss: 0.00134422\n",
            "Batch 110/188 -> Loss: 0.00021627\n",
            "Batch 120/188 -> Loss: 0.00003909\n",
            "Batch 130/188 -> Loss: 0.00000570\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0d1261d8aedf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-bb6d032c5649>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Set model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-c771c42542b2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_pretrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mtform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffineTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Make sure the transform is exactly metric, to ensure fast warping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/transform/_geometric.py\u001b[0m in \u001b[0;36mestimate\u001b[0;34m(self, src, dst)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;31m# De-center and de-normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_matrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0msrc_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Md_4ct1MdL9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}